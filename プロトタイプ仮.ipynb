{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO8SiXZPn0Hy5HCxbPKPm0e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"oya1RSveHF2B","executionInfo":{"status":"ok","timestamp":1752042144551,"user_tz":-540,"elapsed":86189,"user":{"displayName":"筧田仁悠","userId":"09660095884787848289"}}},"outputs":[],"source":["# 各種インポート\n","%%capture\n","!pip install transformers\n","!pip install sentencepiece\n","!pip install fugashi unidic-lite\n","!pip install ipadic\n","import torch\n","from transformers import BertForPreTraining\n","from transformers import BertJapaneseTokenizer, BertModel\n","import logging\n","import numpy as np\n","logging.basicConfig(level=logging.ERROR)\n","tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-v2')\n","model = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-v2')"]},{"cell_type":"code","source":["# Colab内にファイルを作成\n","with open('safe.txt', 'a'):\n","    print(\"safe.txt を作成しました。\")\n","with open('out.txt', 'a'):\n","    print(\"out.txt を作成しました。\")\n","with open('different_sim.txt', 'a'):\n","    print(\"different_sim.txt を作成しました。\")"],"metadata":{"id":"w5bQXKn8IkN_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752042144587,"user_tz":-540,"elapsed":25,"user":{"displayName":"筧田仁悠","userId":"09660095884787848289"}},"outputId":"ed42a52d-f123-4ac9-f68f-ae648f51cee7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["safe.txt を作成しました。\n","out.txt を作成しました。\n","different_sim.txt を作成しました。\n"]}]},{"cell_type":"code","source":["#関数保管場所\n","#safe,outファイルを読み込み\n","def lode_file(filename):\n","    texts, scores = [], []\n","    with open(filename, \"r\", encoding=\"utf-8\") as file:\n","        for line in file:\n","            word, score = line.strip().split(',')\n","            texts.append(word)\n","            scores.append(score)\n","    return texts, scores\n","\n","#ベクトル化処理\n","def text_vec(text):\n","    tmp = tokenizer.encode_plus(text, truncation=True, padding=False, return_tensors='pt')\n","    outputs = model(**tmp)\n","    return outputs.pooler_output.detach().numpy()[0]\n","\n","#ファイルのベクトル化\n","def list_vec(texts_list, scores_list, label):\n","    vectors, sources = [], []\n","    for text, score in zip(texts_list, scores_list):\n","        vectors.append(text_vec(text))\n","        sources.append((text, label, score))\n","    return vectors, sources\n","\n","#コサイン類似度を求める\n","def comp_sim(qvec,tvec):\n","    return np.dot(qvec, tvec) / (np.linalg.norm(qvec) * np.linalg.norm(tvec))\n","\n","\n","#listの平均値算出\n","def average_file(filename):\n","    number = []\n","    with open(filename, 'r', encoding=\"utf-8\") as file:\n","         for line in file:\n","             number.append(float(line.strip()))\n","    return float(sum(number) / len(number)) if len(number) != 0 else 0.75"],"metadata":{"id":"VEYDt2w4IlSz","executionInfo":{"status":"ok","timestamp":1752042144609,"user_tz":-540,"elapsed":19,"user":{"displayName":"筧田仁悠","userId":"09660095884787848289"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#safe,outファイルを読み込みベクトル化\n","text_safe, score_safe = lode_file(\"safe.txt\")\n","text_out, score_out = lode_file(\"out.txt\")\n","\n","vec_safe, sources_safe = list_vec(text_safe, score_safe, label=\"safe\")\n","\n","vec_out, sources_out = list_vec(text_out, score_out, label=\"out\")\n","\n","vec = vec_safe + vec_out\n","text_sources = sources_safe + sources_out\n"],"metadata":{"id":"e99vVq4yYl-o","executionInfo":{"status":"ok","timestamp":1752042529439,"user_tz":-540,"elapsed":90825,"user":{"displayName":"筧田仁悠","userId":"09660095884787848289"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ki9D7zJtSU3U","executionInfo":{"status":"ok","timestamp":1752042144632,"user_tz":-540,"elapsed":7,"user":{"displayName":"筧田仁悠","userId":"09660095884787848289"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#text_xを受け取りベクトル化、類似度を測り、判定を出力\n","similarity_score = []\n","defferent_sim = []\n","\n","text_x = input('判定したいテキストを入力して下さい：')\n","\n","vec_x = text_vec(text_x)\n","\n","for tvec in vec:\n","    similarities = comp_sim(vec_x, tvec)\n","    similarity_score.append(similarities)\n","most_similar_index = np.argmax(similarity_score)\n","most_similar_text, source_file ,B = text_sources[most_similar_index]\n","most_similar_score = similarity_score[most_similar_index]\n","\n","F = 210970\n","F = int(input(\"フォロワー数：\"))\n","if source_file == \"safe\":\n","    P = 0\n","elif source_file == \"out\":\n","    P = 1\n","I = int(F * 0.3 + F ** 0.1 * (1 + 210970 * (int(B) / 100) ** 3.2 * (1 + 0.5 * (int(B) / 100) ** 5 * P)))\n","R = int(I * 0.01 * (1 + 2 * (int(B) / 100) ** 2) * (1 + P))\n","L = int(I * 0.03 * (1 + 0.5 * (int(B) / 100) ** 0.7) * (1 + 0.1 * P))\n","print(\"似ている文：\" + most_similar_text + \"、類似度：\" + str(most_similar_score))\n","print(\"インプレッション数：\" + str(I) + \"、リポスト数：\" + str(R) + \"、いいね数：\" + str(L))\n","if most_similar_score < average_file('different_sim.txt'): # 卍要検討卍\n","  print(\"判定不可\")\n","else:\n","  if \"safe\" in source_file:\n","      print(\"判定：SAFE、バズスコア：\" + B)\n","  elif \"out\" in source_file:\n","      print(\"判定：OUT、バズスコア：\" + B)\n","\n","check = str(input('あなたの判定は？(safe/out):'))\n","\n","if check != source_file:\n","    with open('different_sim.txt', 'a', encoding=\"utf-8\") as file:\n","        file.write(str(similarities))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aE2gkVdvmwRX","executionInfo":{"status":"ok","timestamp":1752042570722,"user_tz":-540,"elapsed":32627,"user":{"displayName":"筧田仁悠","userId":"09660095884787848289"}},"outputId":"29139d4f-75e3-4e97-dd4b-c1c4c4d6f9eb"},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":["判定したいテキストを入力して下さい：地球温暖化とかさいこー\n","フォロワー数：100\n","似ている文：日本社会は変わらなすぎる、類似度：0.75152385\n","インプレッション数：7136、リポスト数：168、いいね数：286\n","判定：OUT、バズスコア：30\n","あなたの判定は？(safe/out):safe\n"]}]}]}